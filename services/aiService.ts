import { Audio } from 'expo-av';
import * as FileSystem from 'expo-file-system/legacy';

const STT_WS_URL = 'ws://localhost:5001/ws/stt';
const CHUNK_INTERVAL_MS = 220;
const FIRST_CHUNK_DELAY_MS = 120;

type TranscriptionHandler = (text: string) => void;
type StatusHandler = (status: string) => void;
type TTSAudioHandler = (audioUri: string) => void;
type RecordingForLipsyncHandler = (audioUri: string) => void;

class AIService {
  private recording: Audio.Recording | null = null;
  private sttSocket: WebSocket | null = null;
  private transcriptionHandlers = new Set<TranscriptionHandler>();
  private statusHandlers = new Set<StatusHandler>();
  private ttsAudioHandlers = new Set<TTSAudioHandler>();
  private recordingForLipsyncHandlers = new Set<RecordingForLipsyncHandler>();
  private socketReady: Promise<void> | null = null;
  private chunkTimer: ReturnType<typeof setTimeout> | null = null;
  private isStreaming = false;
  private isStartingRecording = false;
  private currentVoice: string | null = null;
  private voiceConfigSent = false;

  onTranscription(handler: TranscriptionHandler) {
    this.transcriptionHandlers.add(handler);
  }

  offTranscription(handler: TranscriptionHandler) {
    this.transcriptionHandlers.delete(handler);
  }

  onSocketStatus(handler: StatusHandler) {
    this.statusHandlers.add(handler);
  }

  offSocketStatus(handler: StatusHandler) {
    this.statusHandlers.delete(handler);
  }

  onTTSAudio(handler: TTSAudioHandler) {
    this.ttsAudioHandlers.add(handler);
  }

  offTTSAudio(handler: TTSAudioHandler) {
    this.ttsAudioHandlers.delete(handler);
  }

  onRecordingForLipsync(handler: RecordingForLipsyncHandler) {
    this.recordingForLipsyncHandlers.add(handler);
  }

  offRecordingForLipsync(handler: RecordingForLipsyncHandler) {
    this.recordingForLipsyncHandlers.delete(handler);
  }

  private notifyStatus(status: string) {
    this.statusHandlers.forEach(cb => cb(status));
  }

  private notifyTranscription(text: string) {
    this.transcriptionHandlers.forEach(cb => cb(text));
  }

  setVoice(voice: string) {
    if (voice && voice.trim().length > 0) {
      const newVoice = voice.trim();
      // Eƒüer voice deƒüi≈ütiyse, config'i tekrar g√∂nder
      if (this.currentVoice !== newVoice) {
        this.currentVoice = newVoice;
        this.voiceConfigSent = false; // Yeni voice i√ßin config'i tekrar g√∂nder
        console.log(`üéôÔ∏è Voice set edildi: ${this.currentVoice}`);
        this.sendVoiceConfig();
      }
    } else {
      console.warn('‚ö†Ô∏è Voice bilgisi bo≈ü veya ge√ßersiz');
    }
  }

  private sendVoiceConfig() {
    if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN && this.currentVoice && !this.voiceConfigSent) {
      const configMessage = JSON.stringify({
        type: 'config',
        voice: this.currentVoice
      });
      this.sttSocket.send(configMessage);
      this.voiceConfigSent = true;
      console.log(`üì§ Voice config mesajƒ± g√∂nderildi: ${this.currentVoice}`);
    } else {
      if (!this.sttSocket) {
        // Socket hen√ºz olu≈üturulmamƒ±≈ü, sessizce bekle
      } else if (this.sttSocket.readyState !== WebSocket.OPEN) {
        // Socket hen√ºz a√ßƒ±k deƒüil, sessizce bekle
      } else if (!this.currentVoice) {
        console.log('‚ö†Ô∏è Voice hen√ºz set edilmemi≈ü, voice config g√∂nderilemedi');
      } else if (this.voiceConfigSent) {
        // Config zaten g√∂nderilmi≈ü, tekrar g√∂nderme
      }
    }
  }

  private connectSttSocket() {
    if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN) {
      return;
    }

    this.socketReady = new Promise((resolve, reject) => {
      try {
        // Voice bilgisini query parameter olarak ekle
        const voiceParam = this.currentVoice ? `?voice=${encodeURIComponent(this.currentVoice)}` : '';
        const wsUrl = `${STT_WS_URL}${voiceParam}`;
        console.log(`üîå WebSocket baƒülantƒ±sƒ± kuruluyor: ${wsUrl}`);
        this.sttSocket = new WebSocket(wsUrl);
        this.sttSocket.binaryType = 'arraybuffer';

        this.sttSocket.onopen = () => {
          this.notifyStatus('WebSocket baƒülandƒ±');
          // Voice config'i hemen g√∂nder (eƒüer voice set edilmi≈üse)
          // K√º√ß√ºk bir delay ekleyerek mesajƒ±n g√∂nderildiƒüinden emin ol
          setTimeout(() => {
            if (this.currentVoice) {
              this.voiceConfigSent = false; // Socket yeniden baƒülandƒ±, config'i tekrar g√∂nder
              this.sendVoiceConfig();
            } else {
              console.warn('‚ö†Ô∏è WebSocket baƒülandƒ± ama voice hen√ºz set edilmemi≈ü');
            }
          }, 50); // 50ms delay ile mesajƒ±n g√∂nderildiƒüinden emin ol
          resolve();
        };

        this.sttSocket.onmessage = (event: any) => {
          try {
            if (typeof event.data !== 'string') {
              return;
            }
            const message = JSON.parse(event.data);
            switch (message.type) {
              case 'stt_chunk':
              case 'transcription_complete':
                if (message.text) {
                  this.notifyTranscription(message.text);
                }
                break;
              case 'llm_response':
                if (message.text) {
                  this.notifyStatus(`AI: ${message.text}`);
                }
                break;
              case 'tts_audio':
                if (message.audio) {
                  this.enqueueTTSAudio(message.audio, message.mimeType);
                }
                break;
              case 'error':
                this.notifyStatus(message.message || 'STT hatasƒ±');
                break;
              default:
                break;
            }
          } catch (error) {
            console.error('WebSocket mesaj parse hatasƒ±:', error);
          }
        };

        this.sttSocket.onerror = () => {
          this.notifyStatus('WebSocket hatasƒ±');
          reject(new Error('WebSocket error'));
        };

        this.sttSocket.onclose = () => {
          this.notifyStatus('WebSocket kapandƒ±');
          this.sttSocket = null;
          this.socketReady = null;
          this.voiceConfigSent = false; // Socket kapandƒ±, config'i tekrar g√∂ndermek i√ßin flag'i sƒ±fƒ±rla
        };
      } catch (error) {
        this.notifyStatus('WebSocket olu≈üturulamadƒ±');
        this.socketReady = null;
        reject(error);
      }
    });
  }

  private disconnectSttSocket() {
    if (this.sttSocket) {
      this.sttSocket.close();
      this.sttSocket = null;
    }
    this.socketReady = null;
  }

  private async ensureSocket() {
    if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN) {
      // Socket zaten a√ßƒ±ksa, voice config'i g√∂nder (eƒüer voice set edilmi≈üse ama hen√ºz g√∂nderilmemi≈üse)
      if (this.currentVoice && !this.voiceConfigSent) {
        this.sendVoiceConfig();
      }
      return;
    }

    if (!this.socketReady) {
      this.connectSttSocket();
    }

    if (this.socketReady) {
      await this.socketReady;
      // Socket baƒülandƒ±ktan sonra voice config'i g√∂nder (eƒüer voice set edilmi≈üse)
      // onopen i√ßinde zaten g√∂nderiliyor, burada tekrar g√∂ndermeye gerek yok
    }
  }

  private async startRecordingInstance(): Promise<boolean> {
    if (this.isStartingRecording) {
      return false;
    }

    try {
      this.isStartingRecording = true;

      const permission = await Audio.requestPermissionsAsync();
      if (permission.status !== 'granted') {
        throw new Error('Mikrofon izni reddedildi');
      }

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
      });

      const { recording } = await Audio.Recording.createAsync(
        Audio.RecordingOptionsPresets.HIGH_QUALITY
      );

      this.recording = recording;
      return true;
    } catch (error) {
      console.error('Kayƒ±t ba≈ülatma hatasƒ±:', error);
      return false;
    } finally {
      this.isStartingRecording = false;
    }
  }

  private async stopRecordingInstance(): Promise<string | null> {
    try {
      if (!this.recording) {
        return null;
      }

      await this.recording.stopAndUnloadAsync();
      const uri = this.recording.getURI();
      this.recording = null;
      return uri;
    } catch (error) {
      console.error('Kayƒ±t durdurma hatasƒ±:', error);
      return null;
    }
  }

  private decodeBase64(base64: string): string {
    if (typeof globalThis.atob === 'function') {
      return globalThis.atob(base64);
    }

    const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';
    let output = '';
    let buffer: number;
    let bc = 0;
    let bs = 0;
    let idx = 0;
    const sanitized = base64.replace(/=+$/, '');

    if (sanitized.length % 4 === 1) {
      throw new Error('Ge√ßersiz base64 verisi');
    }

    while ((buffer = sanitized.charCodeAt(idx++))) {
      const charIndex = chars.indexOf(String.fromCharCode(buffer));
      if (charIndex === -1) {
        continue;
      }
      bs = bc % 4 ? bs * 64 + charIndex : charIndex;
      if (bc++ % 4) {
        output += String.fromCharCode(0xff & (bs >> ((-2 * bc) & 6)));
      }
    }

    return output;
  }

  private base64ToArrayBuffer(base64: string): ArrayBuffer {
    const binaryString = this.decodeBase64(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  }

  private async sendBinaryAudio(audioUri: string) {
    await this.ensureSocket();
    if (!this.sttSocket || this.sttSocket.readyState !== WebSocket.OPEN) {
      throw new Error('WebSocket baƒülƒ± deƒüil');
    }

    const base64Data = await FileSystem.readAsStringAsync(audioUri, {
      encoding: FileSystem.EncodingType.Base64,
    });

    const audioBuffer = this.base64ToArrayBuffer(base64Data);
    this.sttSocket.send(audioBuffer);
  }

  private clearChunkTimer() {
    if (this.chunkTimer) {
      clearTimeout(this.chunkTimer);
      this.chunkTimer = null;
    }
  }

  private scheduleChunkDispatch(delay: number = CHUNK_INTERVAL_MS) {
    this.clearChunkTimer();
    this.chunkTimer = setTimeout(async () => {
      if (!this.isStreaming) {
        return;
      }
      try {
        await this.rotateRecording(false);
        this.scheduleChunkDispatch();
      } catch (error) {
        console.error('Chunk g√∂nderilirken hata:', error);
        this.notifyStatus('Ses g√∂nderilemedi');
        await this.stopLiveTranscription();
      }
    }, delay);
  }

  private async rotateRecording(isFinal: boolean) {
    const audioUri = await this.stopRecordingInstance();
    if (!audioUri) {
      return;
    }

    // Send to STT for transcription
    await this.sendBinaryAudio(audioUri);
    
    // If this is the final recording, notify lipsync handlers
    if (isFinal) {
      // Copy the file before deleting (for lipsync)
      const lipsyncAudioUri = `${FileSystem.cacheDirectory}lipsync_${Date.now()}.m4a`;
      try {
        const base64Data = await FileSystem.readAsStringAsync(audioUri, {
          encoding: FileSystem.EncodingType.Base64,
        });
        await FileSystem.writeAsStringAsync(lipsyncAudioUri, base64Data, {
          encoding: FileSystem.EncodingType.Base64,
        });
        // Notify handlers about the recording for lipsync
        this.recordingForLipsyncHandlers.forEach(handler => handler(lipsyncAudioUri));
      } catch (error) {
        console.error('Lipsync audio kopyalanamadƒ±:', error);
      }
      
      if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN) {
        this.sttSocket.send(JSON.stringify({ type: 'speech_end' }));
      }
    }
    
    await FileSystem.deleteAsync(audioUri, { idempotent: true });

    if (!isFinal) {
      const restarted = await this.startRecordingInstance();
      if (!restarted) {
        throw new Error('Yeni kayƒ±t ba≈ülatƒ±lamadƒ±');
      }
    }
  }

  async startLiveTranscription(voice: string): Promise<boolean> {
    if (this.isStreaming) {
      return false;
    }

    if (!voice || !voice.trim()) {
      console.error('‚ùå Voice bilgisi gerekli');
      return false;
    }

    // Voice'u set et
    this.currentVoice = voice.trim();
    console.log(`üéôÔ∏è Voice set edildi: ${this.currentVoice}`);
    
    // Eƒüer socket zaten a√ßƒ±ksa ve voice deƒüi≈ütiyse, yeniden baƒülan
    if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN) {
      // Voice deƒüi≈ütiyse socket'i kapat ve yeniden baƒülan
      if (this.currentVoice) {
        console.log('üîÑ Voice deƒüi≈üti, socket yeniden baƒülanƒ±yor...');
        this.disconnectSttSocket();
      }
    }
    
    // Socket'i baƒüla (voice query parameter olarak g√∂nderilecek)
    await this.ensureSocket();
    
    // Socket baƒülandƒ±ktan sonra ek olarak config mesajƒ± da g√∂nder (fallback)
    if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN) {
      // Config mesajƒ±nƒ± da g√∂nder (query parameter yeterli olmayabilir)
      const configMessage = JSON.stringify({
        type: 'config',
        voice: this.currentVoice
      });
      this.sttSocket.send(configMessage);
      this.voiceConfigSent = true;
      console.log(`üì§ Voice config mesajƒ± g√∂nderildi (fallback): ${this.currentVoice}`);
      
      // Config mesajƒ±nƒ±n server'a ula≈ümasƒ± i√ßin kƒ±sa bir bekleme
      await new Promise(resolve => setTimeout(resolve, 100));
    } else {
      console.error('‚ùå Socket baƒülƒ± deƒüil, voice config g√∂nderilemedi');
      return false;
    }

    const started = await this.startRecordingInstance();
    if (!started) {
      return false;
    }

    this.isStreaming = true;
    this.scheduleChunkDispatch(FIRST_CHUNK_DELAY_MS);
    return true;
  }

  async stopLiveTranscription(): Promise<void> {
    if (!this.isStreaming && !this.recording) {
      return;
    }

    this.isStreaming = false;
    this.clearChunkTimer();

    if (this.recording) {
      await this.rotateRecording(true);
    } else if (this.sttSocket && this.sttSocket.readyState === WebSocket.OPEN) {
      this.sttSocket.send(JSON.stringify({ type: 'speech_end' }));
    }
  }

  async cleanup(): Promise<void> {
    await this.stopLiveTranscription();
    this.disconnectSttSocket();
  }

  private async enqueueTTSAudio(base64Audio: string, mimeType: string = 'audio/mpeg') {
    try {
      const extension = mimeType.includes('wav') ? 'wav' : 'mp3';
      const fileUri = `${FileSystem.cacheDirectory}tts_${Date.now()}.${extension}`;
      await FileSystem.writeAsStringAsync(fileUri, base64Audio, {
        encoding: FileSystem.EncodingType.Base64
      });
      // Notify handlers about the TTS audio file (for sending to conversation)
      // Local playback disabled - audio will come from stream
      this.ttsAudioHandlers.forEach(handler => handler(fileUri));
      // Clean up file after a delay (handlers should have sent it by then)
      setTimeout(() => {
        FileSystem.deleteAsync(fileUri, { idempotent: true }).catch(() => {});
      }, 5000);
    } catch (error) {
      console.error('TTS dosyasƒ± olu≈üturulamadƒ±:', error);
    }
  }

}

export default new AIService();
